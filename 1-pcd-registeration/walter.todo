[x] create 4 files with corrected gps positions (4 scenes)
[x] check scene02,03 and 04 
[x] calculate initial transformation matrix for all frames based on UTM position
   [x] 4.1 convert gps position into utm (in python)
[x] create one file for each timestamp (in gps data)
[x] create one file for each timestamp (in imu data)
[x] match timestamps scene 01, 02 ,03 ,04 (robosense_lidar_base, ouster_lidar, valeo_north_west_lidar, gps_robosense, imu_robosense, s1_camera, s2_camera, vehicle_camera)
[x] extend point cloud registration script to use multiple input files (robosense_lidar + ouster_lidar)
[x] publish registered point cloud and record video
[x] try with initial registration = True
[x] try with initial registration loops set to [4, 8, 12]
[x] manually register single frame (8155_300) 
[x] apply transformation matrix gps/rtk to robosense lidar
[x] test registration by manually shifting point cloud by 1 meter
[x] try point-to-plane ICP for refinement step
[x] cut sequence to 30 seconds (from 50 seconds) or start at ID=50 -> makes registration easier because more overlapping
[x] cut vehicle point cloud to 100 x 100 m (from 200 x 200 m) -> easier for registration
[x] try with different voxel size set to [0.5, 1.0, 2.0, 3.0] 
[x] try with different distance thresholds set to [0.5 0.8, 1.0, 1.5]
[x] manually register last frame (idx=499)
[x] manually register frame 0, then use that transformation matrix for next frame, then apply ICP
[ ] fix initial_transformaion_matrix bug
[ ] try refinement step with point to plane with radius=1.0
[ ] publish uncut point clouds 
[ ] register valeo + ouster lidar to increase density (makes registration easier)
[ ] remove ground from infrastructure lidar -> makes registration easier
[ ] try predator registration algorithm from 2021 (pretrained on kitti)
[x] store colors (red/green) in registered point clouds